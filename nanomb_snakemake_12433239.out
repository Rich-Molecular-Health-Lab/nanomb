[env_setup]
WORK                = /work/richlab/aliciarich
NRDSTOR             = /mnt/nrdstor/richlab/aliciarich
PROJ_ROOT           = /mnt/nrdstor/richlab/shared/nanomb
OUT_ROOT            = /work/richlab/aliciarich/datasets/16s
LOCAL_WORK          = /work/richlab/aliciarich/datasets/16s/_local_work
APPTAINER_CACHEDIR  = /mnt/nrdstor/richlab/aliciarich/.apptainer/cache
APPTAINER_TMPDIR    = /mnt/nrdstor/richlab/aliciarich/.apptainer/tmp
Using profile profiles/hcc for setting default command line arguments.
host: c2015.swan.hcc.unl.edu
Building DAG of jobs...
Need to rerun job iqtree2_tree because job otu_alignment has to be rerun.
Need to rerun job all because job otu_alignment has to be rerun.
Need to rerun job all because job iqtree2_tree has to be rerun.
Need to rerun job otu_table_per_sample because of missing output required by all.
Need to rerun job all because job otu_table_per_sample has to be rerun.
/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_table_merged.tsv: True 0
/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta: True 0
/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_tree.treefile: False 1
: False 3
shared_storage_local_copies: True
remote_exec: False
Submitting maximum 100 job(s) over 1.0 second(s).
You are running snakemake in a SLURM job context. This is not recommended, as it may lead to unexpected behavior. Please run Snakemake directly on the login node.
SLURM run ID: 453d0481-db69-4646-b234-d3146e2cea50
Using shell: /usr/bin/bash
Provided remote nodes: 16
Job stats:
job                     count
--------------------  -------
all                         1
iqtree2_tree                1
otu_alignment               1
otu_table_per_sample        1
total                       4

Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 16, '_job_count': 9223372036854775807}
Ready jobs: 2
Select jobs to execute...
Welcome to the CBC MILP Solver 
Version: 2.10.12 
Build Date: Mar  5 2025 

command line - cbc /mnt/nrdstor/richlab/aliciarich/tmp/bc6b5b23f9e84bbbbd85b818a33930d3-pulp.mps -max -sec 10 -threads 2 -timeMode elapsed -branch -printingOptions all -solution /mnt/nrdstor/richlab/aliciarich/tmp/bc6b5b23f9e84bbbbd85b818a33930d3-pulp.sol (default strategy 1)
At line 2 NAME          MODEL
At line 3 ROWS
At line 8 COLUMNS
At line 21 RHS
At line 25 BOUNDS
At line 28 ENDATA
Problem MODEL has 3 rows, 2 columns and 6 elements
Coin0008I MODEL read with 0 errors
seconds was changed from 1e+100 to 10
No match for threads - ? for list of commands
No match for 2 - ? for list of commands
Option for timeMode changed from cpu to elapsed
Continuous objective value is 64 - 0.00 seconds
Cgl0004I processed model has 0 rows, 0 columns (0 integer (0 of which binary)) and 0 elements
Cbc3007W No integer variables - nothing to do
Cuts at root node changed objective from 64 to 1.79769e+308
Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)
Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)
Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)
Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)
MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)
FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)
TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)
ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)

Result - Optimal solution found

Objective value:                64.00000000
Enumerated nodes:               0
Total iterations:               0
Time (CPU seconds):             0.00
Time (Wallclock seconds):       0.00

Option for printingOptions changed from normal to all
Total time (CPU seconds):       0.03   (Wallclock seconds):       0.01

Selected jobs: 2
Resources after job selection: {'_cores': 9223372036854775775, '_nodes': 14, '_job_count': 100}
Execute 2 jobs...

[Thu Oct  9 11:03:01 2025]
rule otu_table_per_sample:
    input: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_clean.fasta, /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/filtered
    output: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_table_merged.tsv
    jobid: 32
    reason: Missing output files: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_table_merged.tsv
    threads: 16
    resources: mem_mb=16000, mem_mib=15259, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, runtime=180, partition=batch, account=richlab, extra=
Shell command: 
      set -euo pipefail
      mkdir -p /work/richlab/aliciarich/datasets/16s/loris/culi/otu/tables
      shopt -s nullglob
      for fq in /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/filtered/*.fastq; do
        sid=$(basename "$fq" .fastq)
        vsearch --usearch_global "$fq" \
                --db /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_clean.fasta \
                --id 0.98 \
                --strand both \
                --otutabout /work/richlab/aliciarich/datasets/16s/loris/culi/otu/tables/otu_table_${sid}.tsv \
                --threads 16
      done
      python - <<'PY'
      import glob, os, pandas as pd
      out = r"/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_table_merged.tsv"
      tables = glob.glob(os.path.join(r"/work/richlab/aliciarich/datasets/16s/loris/culi", "otu", "tables", "otu_table_*.tsv"))
      dfs = [pd.read_csv(t, sep="\t") for t in tables]
      if not dfs:
          raise SystemExit("No per-sample OTU tables found to merge.")
      for d in dfs:
          first = d.columns[0]
          d.rename(columns=dict([(first, "OTU")]), inplace=True)
      from functools import reduce
      merged = reduce(lambda l, r: pd.merge(l, r, on="OTU", how="outer"), dfs).fillna(0)
      merged.to_csv(out, sep="\t", index=False)
      PY
    
No SLURM account given, trying to guess.
Unable to guess SLURM account. Trying to proceed without.
General args: ['--force', '--target-files-omit-workdir-adjustment', '', '--max-inventory-time 0', '--nocolor', '--notemp', '--no-hooks', '--nolock', '--ignore-incomplete', '', '--verbose ', '--rerun-triggers code software-env input mtime params', '', '', '', '--deployment-method apptainer', "--conda-frontend 'conda'", '', '', "--apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer'", '--apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg==', '', '--shared-fs-usage source-cache software-deployment storage-local-copies input-output sources persistence', '', "--wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/'", '', '', '', '--printshellcmds ', '', '--latency-wait 60', "--scheduler 'ilp'", '', '--local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl', "--scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin'", '', '', '', '', '', '', '--default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI=', '']
sbatch call: sbatch --parsable --job-name 453d0481-db69-4646-b234-d3146e2cea50 --output "/mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_otu_table_per_sample/%j.log" --export=ALL --comment "rule_otu_table_per_sample"   -p batch -t 180 --mem 16000 --ntasks=1 --cpus-per-task=16 -D '/mnt/nrdstor/richlab/shared/nanomb' --wrap="/mnt/nrdstor/richlab/aliciarich/snakemake/bin/python3.12 -m snakemake --snakefile '/mnt/nrdstor/richlab/shared/nanomb/Snakefile' --target-jobs 'otu_table_per_sample:' --allowed-rules otu_table_per_sample --cores 'all' --attempt 1 --force-use-threads  --wait-for-files '/mnt/nrdstor/richlab/shared/nanomb/.snakemake/tmp.qlae_ceg' '/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_clean.fasta' '/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/filtered' --force --target-files-omit-workdir-adjustment --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --verbose  --rerun-triggers code software-env input mtime params --deployment-method apptainer --conda-frontend 'conda' --apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer' --apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg== --shared-fs-usage source-cache software-deployment storage-local-copies input-output sources persistence --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 60 --scheduler 'ilp' --local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl --scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin' --default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI= --executor slurm-jobstep --jobs 1 --mode 'remote'"
Job 32 has been submitted with SLURM jobid 12433251 (log: /mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_otu_table_per_sample/12433251.log).

[Thu Oct  9 11:03:01 2025]
rule otu_alignment:
    input: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_clean.fasta
    output: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta
    jobid: 34
    reason: Missing output files: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta; Set of input files has changed since last execution; Code has changed since last execution; Software environment definition has changed since last execution
    threads: 16
    resources: mem_mb=32000, mem_mib=30518, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, runtime=240, partition=batch, account=richlab, extra=
Shell command: 
      set -euo pipefail
      command -v mafft >/dev/null || { echo "mafft not found"; exit 127; }
      mafft --auto --thread 16 "/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_clean.fasta" > "/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta"
    
General args: ['--force', '--target-files-omit-workdir-adjustment', '', '--max-inventory-time 0', '--nocolor', '--notemp', '--no-hooks', '--nolock', '--ignore-incomplete', '', '--verbose ', '--rerun-triggers code software-env input mtime params', '', '', '', '--deployment-method apptainer', "--conda-frontend 'conda'", '', '', "--apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer'", '--apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg==', '', '--shared-fs-usage source-cache software-deployment storage-local-copies input-output sources persistence', '', "--wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/'", '', '', '', '--printshellcmds ', '', '--latency-wait 60', "--scheduler 'ilp'", '', '--local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl', "--scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin'", '', '', '', '', '', '', '--default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI=', '']
sbatch call: sbatch --parsable --job-name 453d0481-db69-4646-b234-d3146e2cea50 --output "/mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_otu_alignment/%j.log" --export=ALL --comment "rule_otu_alignment"   -p batch -t 240 --mem 32000 --ntasks=1 --cpus-per-task=16 -D '/mnt/nrdstor/richlab/shared/nanomb' --wrap="/mnt/nrdstor/richlab/aliciarich/snakemake/bin/python3.12 -m snakemake --snakefile '/mnt/nrdstor/richlab/shared/nanomb/Snakefile' --target-jobs 'otu_alignment:' --allowed-rules otu_alignment --cores 'all' --attempt 1 --force-use-threads  --wait-for-files '/mnt/nrdstor/richlab/shared/nanomb/.snakemake/tmp.qlae_ceg' '/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_clean.fasta' --force --target-files-omit-workdir-adjustment --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --verbose  --rerun-triggers code software-env input mtime params --deployment-method apptainer --conda-frontend 'conda' --apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer' --apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg== --shared-fs-usage source-cache software-deployment storage-local-copies input-output sources persistence --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 60 --scheduler 'ilp' --local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl --scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin' --default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI= --executor slurm-jobstep --jobs 1 --mode 'remote'"
Job 34 has been submitted with SLURM jobid 12433252 (log: /mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_otu_alignment/12433252.log).
Waiting for running jobs to complete.
Checking the status of 2 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-10-07T11:00 --endtime now --name 453d0481-db69-4646-b234-d3146e2cea50
It took: 0.01484227180480957 seconds
The output is:
'12433251|RUNNING
12433252|RUNNING
'

status_of_jobs after sacct is: {'12433251': 'RUNNING', '12433252': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'12433251', '12433252'}
active_jobs_seen_by_sacct are: {'12433251', '12433252'}
missing_sacct_status are: set()
Checking the status of 2 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-10-07T11:00 --endtime now --name 453d0481-db69-4646-b234-d3146e2cea50
It took: 0.014901876449584961 seconds
The output is:
'12433251|RUNNING
12433252|COMPLETED
'

status_of_jobs after sacct is: {'12433251': 'RUNNING', '12433252': 'COMPLETED'}
active_jobs_ids_with_current_sacct_status are: {'12433251', '12433252'}
active_jobs_seen_by_sacct are: {'12433251', '12433252'}
missing_sacct_status are: set()
removing log for successful job with SLURM ID '12433252'
[Thu Oct  9 11:03:56 2025]
Finished jobid: 34 (Rule: otu_alignment)
1 of 4 steps (25%) done
/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_tree.treefile: True 0
: False 2
Resources before job selection: {'_cores': 9223372036854775791, '_nodes': 15, '_job_count': 100}
Ready jobs: 1
Select jobs to execute...
Selecting jobs to run using greedy solver.
Selected jobs: 1
Resources after job selection: {'_cores': 9223372036854775775, '_nodes': 14, '_job_count': 100}
Execute 1 jobs...

[Thu Oct  9 11:03:56 2025]
rule iqtree2_tree:
    input: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta
    output: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_tree.treefile
    log: /work/richlab/aliciarich/datasets/16s/loris/culi/logs/iqtree2_tree.log
    jobid: 35
    reason: Missing output files: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_tree.treefile; Input files updated by another job: /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta
    threads: 16
    resources: mem_mb=64000, mem_mib=61036, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, runtime=720, partition=batch, account=richlab, extra=
Shell command: 
      set -euo pipefail
      iqtree2 -s /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta -nt AUTO -m TEST -bb 1000 -alrt 1000 \
              -pre /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_tree
      test -s /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_tree.treefile
    
General args: ['--force', '--target-files-omit-workdir-adjustment', '', '--max-inventory-time 0', '--nocolor', '--notemp', '--no-hooks', '--nolock', '--ignore-incomplete', '', '--verbose ', '--rerun-triggers code software-env input mtime params', '', '', '', '--deployment-method apptainer', "--conda-frontend 'conda'", '', '', "--apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer'", '--apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg==', '', '--shared-fs-usage source-cache software-deployment storage-local-copies input-output sources persistence', '', "--wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/'", '', '', '', '--printshellcmds ', '', '--latency-wait 60', "--scheduler 'ilp'", '', '--local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl', "--scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin'", '', '', '', '', '', '', '--default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI=', '']
sbatch call: sbatch --parsable --job-name 453d0481-db69-4646-b234-d3146e2cea50 --output "/mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_iqtree2_tree/%j.log" --export=ALL --comment "rule_iqtree2_tree"   -p batch -t 720 --mem 64000 --ntasks=1 --cpus-per-task=16 -D '/mnt/nrdstor/richlab/shared/nanomb' --wrap="/mnt/nrdstor/richlab/aliciarich/snakemake/bin/python3.12 -m snakemake --snakefile '/mnt/nrdstor/richlab/shared/nanomb/Snakefile' --target-jobs 'iqtree2_tree:' --allowed-rules iqtree2_tree --cores 'all' --attempt 1 --force-use-threads  --wait-for-files '/mnt/nrdstor/richlab/shared/nanomb/.snakemake/tmp.qlae_ceg' '/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta' --force --target-files-omit-workdir-adjustment --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --verbose  --rerun-triggers code software-env input mtime params --deployment-method apptainer --conda-frontend 'conda' --apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer' --apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg== --shared-fs-usage source-cache software-deployment storage-local-copies input-output sources persistence --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 60 --scheduler 'ilp' --local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl --scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin' --default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI= --executor slurm-jobstep --jobs 1 --mode 'remote'"
Job 35 has been submitted with SLURM jobid 12433257 (log: /mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_iqtree2_tree/12433257.log).
Waiting for running jobs to complete.
Checking the status of 2 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-10-07T11:00 --endtime now --name 453d0481-db69-4646-b234-d3146e2cea50
It took: 0.015387773513793945 seconds
The output is:
'12433251|RUNNING
12433252|COMPLETED
12433257|PENDING
'

status_of_jobs after sacct is: {'12433251': 'RUNNING', '12433252': 'COMPLETED', '12433257': 'PENDING'}
active_jobs_ids_with_current_sacct_status are: {'12433257', '12433251'}
active_jobs_seen_by_sacct are: {'12433257', '12433251'}
missing_sacct_status are: set()
Checking the status of 2 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-10-07T11:00 --endtime now --name 453d0481-db69-4646-b234-d3146e2cea50
It took: 0.013821601867675781 seconds
The output is:
'12433251|RUNNING
12433252|COMPLETED
12433257|PENDING
'

status_of_jobs after sacct is: {'12433251': 'RUNNING', '12433252': 'COMPLETED', '12433257': 'PENDING'}
active_jobs_ids_with_current_sacct_status are: {'12433257', '12433251'}
active_jobs_seen_by_sacct are: {'12433257', '12433251'}
missing_sacct_status are: set()
