[env_setup]
WORK                = /work/richlab/aliciarich
NRDSTOR             = /mnt/nrdstor/richlab/aliciarich
PROJ_ROOT           = /mnt/nrdstor/richlab/shared/nanomb
OUT_ROOT            = /work/richlab/aliciarich/datasets/16s
LOCAL_WORK          = /work/richlab/aliciarich/datasets/16s/_local_work
APPTAINER_CACHEDIR  = /mnt/nrdstor/richlab/aliciarich/.apptainer/cache
APPTAINER_TMPDIR    = /mnt/nrdstor/richlab/aliciarich/.apptainer/tmp
Using profile profiles/hcc for setting default command line arguments.
host: c1526.swan.hcc.unl.edu
Building DAG of jobs...
Need to rerun job racon_round1 because job map_all_reads has to be rerun.
Need to rerun job map_r1 because job map_all_reads has to be rerun.
Need to rerun job racon_round2 because job map_all_reads has to be rerun.
Need to rerun job medaka_polish because job map_all_reads has to be rerun.
Need to rerun job map_r1 because job racon_round1 has to be rerun.
Need to rerun job racon_round2 because job racon_round1 has to be rerun.
Need to rerun job racon_round2 because job map_r1 has to be rerun.
Need to rerun job medaka_polish because job racon_round2 has to be rerun.
Need to rerun job chimera_taxonomy_tree because job medaka_polish has to be rerun.
Need to rerun job all because job medaka_polish has to be rerun.
Need to rerun job otu_table_per_sample because job chimera_taxonomy_tree has to be rerun.
Need to rerun job iqtree2_tree because job chimera_taxonomy_tree has to be rerun.
Need to rerun job all because job chimera_taxonomy_tree has to be rerun.
Need to rerun job all because job otu_table_per_sample has to be rerun.
Need to rerun job all because job iqtree2_tree has to be rerun.
/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/r2.fasta: False 3
/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_table_merged.tsv: False 1
/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/r1.fasta: False 1
/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_tree.treefile: False 1
: False 4
/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/all_reads.fastq /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/map_r0.bam: True 0
/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/polished_otus.fasta: False 2
/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/map_r1.bam: False 2
/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_clean.fasta /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_chimeras.fasta /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_taxonomy.sintax /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otu_references_aligned.fasta: False 1
shared_storage_local_copies: True
remote_exec: False
Submitting maximum 100 job(s) over 1.0 second(s).
You are running snakemake in a SLURM job context. This is not recommended, as it may lead to unexpected behavior. Please run Snakemake directly on the login node.
SLURM run ID: 41b38195-7887-4cdf-9606-f68f30f73887
Using shell: /usr/bin/bash
Provided remote nodes: 16
Job stats:
job                      count
---------------------  -------
all                          1
chimera_taxonomy_tree        1
iqtree2_tree                 1
map_all_reads                1
map_r1                       1
medaka_polish                1
otu_table_per_sample         1
racon_round1                 1
racon_round2                 1
total                        9

Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 16, '_job_count': 9223372036854775807}
Ready jobs: 1
Select jobs to execute...
Selecting jobs to run using greedy solver.
Selected jobs: 1
Resources after job selection: {'_cores': 9223372036854775791, '_nodes': 15, '_job_count': 100}
Execute 1 jobs...

[Tue Oct  7 09:30:20 2025]
rule map_all_reads:
    input: /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/filtered, /work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_centroids_99.fasta
    output: /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/all_reads.fastq, /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/map_r0.bam
    log: /work/richlab/aliciarich/datasets/16s/loris/culi/logs/map_all_reads.log
    jobid: 25
    reason: Missing output files: /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/map_r0.bam, /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/all_reads.fastq; Code has changed since last execution; Params have changed since last execution: Union of exclusive params before and now across all output: before: '/work/richlab/aliciarich/datasets/16s/loris/culi','/work/richlab/aliciarich/datasets/16s/loris/culi/tmp' now: <nothing exclusive> ; Software environment definition has changed since last execution
    threads: 16
    resources: mem_mb=16000, mem_mib=15259, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, runtime=180, partition=batch, account=richlab, extra=
Shell command: 
      set -euo pipefail
      module load minimap2 samtools || true

      mkdir -p "$(dirname /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/all_reads.fastq)" "$(dirname /work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/map_r0.bam)"

      : > "/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/all_reads.fastq"
      find "/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/filtered" -maxdepth 1 -type f -name '*.fastq' -print0 \
        | xargs -0 cat >> "/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/all_reads.fastq"

      minimap2 -t 16 -ax map-ont "/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_centroids_99.fasta" "/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/all_reads.fastq" \
        | samtools sort -@ 16 -m 2G -o "/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/map_r0.bam"

      samtools index "/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/polished/map_r0.bam"
    
No SLURM account given, trying to guess.
Unable to guess SLURM account. Trying to proceed without.
General args: ['--force', '--target-files-omit-workdir-adjustment', '', '--max-inventory-time 0', '--nocolor', '--notemp', '--no-hooks', '--nolock', '--ignore-incomplete', '', '--verbose ', '--rerun-triggers params input software-env mtime code', '', '', '', '--deployment-method apptainer', "--conda-frontend 'conda'", '', '', "--apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer'", '--apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg==', '', '--shared-fs-usage input-output persistence software-deployment storage-local-copies source-cache sources', '', "--wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/'", '', '', '', '--printshellcmds ', '', '--latency-wait 60', "--scheduler 'ilp'", '', '--local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl', "--scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin'", '', '', '', '', '', '', '--default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI=', '']
sbatch call: sbatch --parsable --job-name 41b38195-7887-4cdf-9606-f68f30f73887 --output "/mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_map_all_reads/%j.log" --export=ALL --comment "rule_map_all_reads"   -p batch -t 180 --mem 16000 --ntasks=1 --cpus-per-task=16 -D '/mnt/nrdstor/richlab/shared/nanomb' --wrap="/mnt/nrdstor/richlab/aliciarich/snakemake/bin/python3.12 -m snakemake --snakefile '/mnt/nrdstor/richlab/shared/nanomb/Snakefile' --target-jobs 'map_all_reads:' --allowed-rules map_all_reads --cores 'all' --attempt 1 --force-use-threads  --wait-for-files '/mnt/nrdstor/richlab/shared/nanomb/.snakemake/tmp.oi0chrwl' '/work/richlab/aliciarich/datasets/16s/loris/culi/tmp/filtered' '/work/richlab/aliciarich/datasets/16s/loris/culi/otu/otus_centroids_99.fasta' --force --target-files-omit-workdir-adjustment --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --verbose  --rerun-triggers params input software-env mtime code --deployment-method apptainer --conda-frontend 'conda' --apptainer-prefix '/mnt/nrdstor/richlab/aliciarich/.apptainer' --apptainer-args base64//LS1udiAtLWJpbmQgL3dvcmssL2x1c3RyZSwvbW50L25yZHN0b3IsL2hvbWUsL21udC9ucmRzdG9yL3JpY2hsYWIvc2hhcmVkL2RvcmFkb19tb2RlbHM6L21vZGVscywvbW50L25yZHN0b3IvcmljaGxhYi9zaGFyZWQvZGF0YWJhc2VzOi9yZWZkYg== --shared-fs-usage input-output persistence software-deployment storage-local-copies source-cache sources --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 60 --scheduler 'ilp' --local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl --scheduler-solver-path '/mnt/nrdstor/richlab/aliciarich/snakemake/bin' --default-resources base64//bWVtX21iPTgwMDA= base64//ZGlza19tYj1tYXgoMippbnB1dC5zaXplX21iLCAxMDAwKSBpZiBpbnB1dCBlbHNlIDUwMDAw base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= base64//cnVudGltZT02MA== base64//cGFydGl0aW9uPWJhdGNo base64//YWNjb3VudD1yaWNobGFi base64//ZXh0cmE9IiI= --executor slurm-jobstep --jobs 1 --mode 'remote'"
Job 25 has been submitted with SLURM jobid 12407376 (log: /mnt/nrdstor/richlab/shared/nanomb/.snakemake/slurm_logs/rule_map_all_reads/12407376.log).
Waiting for running jobs to complete.
